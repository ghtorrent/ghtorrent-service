require 'ghtorrent'
require 'bunny'
require 'uri'
require 'queue_stuff'
require 'formats'


class GHTRetrieveRepos < GHTorrent::Command

  include Formats
  include GHTorrent::Settings
  include GHTorrent::Logging

  def logger
    @logger ||= Logger.new(STDOUT)
    @logger
  end

  def prepare_options(options)
    options.banner <<-BANNER
Retrieve data for multiple repos in parallel. To work, it requires
a mapping file formatted as follows:

IP UNAME PASSWD NUM_PROCS where

IP = address to use for outgoing requests (use 0.0.0.0 on non-multihomed hosts)
UNAME = Github user name to use for outgoing requests
PASSWD = Github password to use for outgoing requests
NUM_PROCS = Number of processes to spawn for this IP/UNAME combination

Values in the config.yaml file set with the -c command are overriden.

#{command_name} [options] mapping-file

    BANNER
    options.opt :queue, 'Queue to retrieve project names from',
                :short => 'q', :default => 'retrieve-repo', :type => :string

  end

  def validate
    super
    Trollop::die 'Argument mapping-file is required' unless not args[0].nil?
  end

  def go

    configs = File.open(ARGV[0]).readlines.map do |line|
      next if line =~ /^#/
      ip,name,passwd,instances = line.strip.split(/ /)
      (1..instances.to_i).map do |i|
        newcfg = self.settings.clone
        newcfg = override_config(newcfg, :attach_ip, ip)
        newcfg = override_config(newcfg, :github_username, name)
        newcfg = override_config(newcfg, :github_passwd, passwd)
        newcfg = override_config(newcfg, :mirror_history_pages_back, 1000)
        newcfg = override_config(newcfg, :mirror_commit_pages_new_repo, 1000)
        newcfg
      end
    end.flatten.select{|x| !x.nil?}

    children = configs.map do |config|
      pid = Process::fork

      if pid.nil?
        retriever = GHTRepoRetriever.new(config, options[:queue])

        Signal.trap('TERM') {
          retriever.stop
        }

        retriever.run(self)
        exit
      else
        debug "Parent #{Process.pid} forked child #{pid}"
        pid
      end
    end

    debug 'Waiting for children'
    begin
      children.each do |pid|
        debug "Waiting for child #{pid}"
        Process.waitpid(pid, 0)
        debug "Child #{pid} exited"
      end
    rescue Interrupt
      debug 'Stopping'
    end
  end
end

class GHTRepoRetriever

  include GHTorrent::Settings
  include GHTorrent::Retriever
  include GHTorrent::Persister

  include QueueStuff

  def initialize(config, queue)
    @config = config
    @queue = queue
  end

  def logger
    @logger ||= Logger.new(STDOUT)
  end

  def ght
    @ght ||= TransactedGhtorrent.new(@config)
    @ght
  end

  def settings
    @config
  end

  def run(command)

    job_id, owner, repo = ''

    stopped = false
    while not stopped
      begin
        consumer_queue(JOB_QUEUE, JOB_QUEUE_ROUTEKEY).subscribe(
            :block => true, :ack => true) do |delivery_info, properties, msg|

          amqp_channel.acknowledge(delivery_info.delivery_tag, false)

          job_id, owner, repo = msg.split(/ /)
          db_name = Formats::DB_NAME % job_id

          db_url = URI(config(:sql_url))
          db_url.path = "/#{db_name}"
          @config = merge_config_values(@config, {:sql_url => db_url.to_s})

          case db_url.scheme
            when 'mysql2'
              require 'mysql2'
              lock_name = "/tmp/ghtorrent-srv-#{db_name}.lock"
              client = Mysql2::Client.new(:host => db_url.host,
                                          :username => db_url.user,
                                          :password => db_url.password)
              lock = File.open(lock_name, File::RDWR|File::CREAT, 0644)
              begin
                lock.flock(File::LOCK_EX)
                debug "Checking DB #{db_name}" 
                # grant all PRIVILEGES on `job%`.* to 'ghtorrent'@'localhost';
                # grant all PRIVILEGES on `job%`.* to 'ghtorrent'@'%';
                exists = client.query("SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = '#{db_name}'").to_a
                if exists.empty?
                  client.query("create database if not exists #{db_name} CHARACTER SET = 'utf8'")
                  ght.get_db # Trigger migration run
                end
              ensure
                client.close unless client.nil?
                lock.flock(File::LOCK_UN)
              end
            else
              raise Exception("Unsupported DB type #{db_url.scheme}")
          end

          user_entry = ght.transaction { ght.ensure_user(owner, false, false) }

          if user_entry.nil?
            warn("Cannot find user #{owner}")
            send_job_status(job_id, owner, repo, 'FAILED', "No user #{owner}")
            next
          end

          repo_entry = ght.transaction { ght.ensure_repo(owner, repo) }

          if repo_entry.nil?
            warn("Cannot find repository #{owner}/#{repo}")
            send_job_status(job_id, owner, repo, 'FAILED', "No such repo #{owner}/#{repo}")
            next
          end

          debug("Retrieving repo #{owner}/#{repo}")

          retrieval_stages = %w(ensure_commits ensure_forks ensure_pull_requests
            ensure_issues ensure_project_members ensure_watchers ensure_labels)

          retrieval_stages.each do |x|
            run_retrieval_stage(job_id, owner, repo, x)
          end

          # Repository owner bound data retrieval
          run_retrieval_stage(job_id, owner, repo, 'ensure_user_followers')

          if user_entry[:type] == 'ORG'
            run_retrieval_stage(job_id, owner, repo, 'ensure_org')
          end

          db_close
          send_job_status(job_id, owner, repo, 'FINISHED')
        end

      rescue Bunny::TCPConnectionFailed => e
        warn "Connection to #{config(:amqp_host)} failed. Retrying in 1 sec"
        sleep(1)
      rescue Bunny::PossibleAuthenticationFailureError => e
        warn "Could not authenticate as #{conn.username}"
        stopped = true
      rescue Bunny::NotFound, Bunny::AccessRefused, Bunny::PreconditionFailed => e
        warn "Channel error: #{e}. Retrying in 1 sec"
        sleep(1)
      rescue Interrupt => _
        send_job_status(job_id, owner, repo, 'STOPPED', 'Retrieval stopped on sysadmin request')
        stopped = true
      rescue Exception => e
        send_job_status(job_id, owner, repo, 'FAILED', e.message)
        raise e
      end
    end

    amqp_close
  end

  def send_job_status(job_id, owner, repo, status, details = '')
    amqp_exchange.publish("#{job_id} #{owner} #{repo} #{status} @#{details}@",
                          {:timestamp => Time.now.to_i,
                           :persistent => true,
                           :routing_key => RESULT_QUEUE_ROUTEKEY})
  end

  def run_retrieval_stage(job_id, owner, repo, function)
    begin
      send_job_status(job_id, owner, repo, 'WORKING',
                      "Retrieving #{function.split(/_/)[1..-1].join(' ')}")
      ght.send(function, owner, repo, refresh = false)
    rescue Exception
      warn("Error processing #{function} for #{owner}/#{repo}")
      send_job_status(job_id, owner, repo, 'WORKING',
                      "Failed to retrieve #{function.split(/_/)[1..-1].join(' ')}")
    end
  end

end

GHTRetrieveRepos.run(ARGV)
