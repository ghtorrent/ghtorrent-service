require 'ghtorrent'
require 'bunny'
require 'uri'
require 'queue_stuff'
require 'formats'


class GHTServiceRetrieveRepos < GHTorrent::Command

  include Formats
  include GHTorrent::Settings
  include GHTorrent::Logging

  def logger
    @logger ||= Logger.new(STDOUT)
    @logger
  end

  def prepare_options(options)
    options.banner <<-BANNER
Retrieve data for multiple repos in parallel. To work, it requires
a mapping file formatted as follows:

IP UNAME PASSWD NUM_PROCS where

IP = address to use for outgoing requests (use 0.0.0.0 on non-multihomed hosts)
UNAME = Github user name to use for outgoing requests
PASSWD = Github password to use for outgoing requests
NUM_PROCS = Number of processes to spawn for this IP/UNAME combination

Values in the config.yaml file set with the -c command are overriden.

#{command_name} [options] mapping-file

    BANNER
    options.opt :queue, 'Queue to retrieve project names from',
                :short => 'q', :default => 'retrieve-repo', :type => :string

  end

  def validate
    super
    Trollop::die 'Argument mapping-file is required' unless not args[0].nil?
  end

  def go

    configs = File.open(ARGV[0]).readlines.map do |line|
      next if line =~ /^#/
      ip, name, passwd, instances = line.strip.split(/ /)
      (1..instances.to_i).map do |i|
        newcfg = self.settings.clone
        newcfg = override_config(newcfg, :attach_ip, ip)
        newcfg = override_config(newcfg, :github_username, name)
        newcfg = override_config(newcfg, :github_passwd, passwd)
        newcfg = override_config(newcfg, :mirror_history_pages_back, 1000)
        newcfg = override_config(newcfg, :mirror_commit_pages_new_repo, 1000)
        newcfg
      end
    end.flatten.select { |x| !x.nil? }

    children = configs.map do |config|
      pid = Process::fork

      if pid.nil?
        retriever = GHTRepoRetriever.new(config, options[:queue])

        Signal.trap('TERM') {
          retriever.stop
        }

        retriever.run(self)
        exit
      else
        debug "Parent #{Process.pid} forked child #{pid}"
        pid
      end
    end

    debug 'Waiting for children'
    begin
      children.each do |pid|
        debug "Waiting for child #{pid}"
        Process.waitpid(pid, 0)
        debug "Child #{pid} exited"
      end
    rescue Interrupt
      debug 'Stopping'
    end
  end
end

class GHTRepoRetriever

  include GHTorrent::Settings
  include GHTorrent::Retriever
  include GHTorrent::Persister

  include QueueStuff

  def initialize(config, queue)
    @config = config
    @queue = queue
  end

  def logger
    @logger ||= Logger.new(STDOUT)
  end

  def settings
    @config
  end

  def run(command)

    job_id, owner, repo = ''

    stopped = false
    while not stopped
      begin
        consumer_queue(JOB_QUEUE, JOB_QUEUE_ROUTEKEY).subscribe(
            :block => true, :ack => true) do |delivery_info, properties, msg|

          ght = TransactedGhtorrent.new(@config)
          amqp_channel.acknowledge(delivery_info.delivery_tag, false)

          job_id, owner, repo = msg.split(/ /)
          db_name = Formats::DB_NAME % job_id

          db_url = URI(config(:sql_url))
          db_url.path = "/#{db_name}"
          @config = merge_config_values(@config, {:sql_url => db_url.to_s})

          case db_url.scheme
            when 'mysql2'
              require 'mysql2'
              lock_name = "/tmp/ghtorrent-srv-#{db_name}.lock"
              client = Mysql2::Client.new(:host => db_url.host,
                                          :username => db_url.user,
                                          :password => db_url.password)
              lock = File.open(lock_name, File::RDWR|File::CREAT, 0644)
              begin
                lock.flock(File::LOCK_EX)
                debug "Process #{Process.pid} (parent: #{Process.ppid}): Obtained file lock"
                debug "Process #{Process.pid} (parent: #{Process.ppid}): Checking DB #{db_name}"
                exists = client.query("SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = '#{db_name}'").to_a
                if exists.empty?
                  debug "Process #{Process.pid} (parent: #{Process.ppid}): Creating database #{db_name}"
                  client.query("create database if not exists #{db_name} CHARACTER SET = 'utf8'")
                  ght.get_db # Trigger migration run
                  debug "Process #{Process.pid} (parent: #{Process.ppid}): Finished running migrations #{db_name}"
                else
                  debug "Process #{Process.pid} (parent: #{Process.ppid}): Database #{db_name} exists"
                end
              ensure
                client.close unless client.nil?
                lock.flock(File::LOCK_UN)
              end
            else
              raise Exception("Unsupported DB type #{db_url.scheme}")
          end

          # On rare occasions, 2 instances might try to add the same user
          # at the same time, which might lead to transaction conflicts
          # Give the script one more opportunity before bailing out
          user_entry = nil
          i = 0
          while user_entry.nil? and i < 10 do
            i += 1
            warn("Trying to get user #{owner}, attempt #{i}")
            begin
              user_entry = ght.transaction { ght.ensure_user(owner, false, false) }
            rescue Exception => e
              warn e.message
            end
          end

          if user_entry.nil?
            warn("Cannot find user #{owner}")
            send_job_status(job_id, owner, repo, 'FAILED', "No user #{owner}")
            ght.dispose
            next
          end

          repo_entry = ght.transaction { ght.ensure_repo(owner, repo) }

          if repo_entry.nil?
            warn("Cannot find repository #{owner}/#{repo}")
            send_job_status(job_id, owner, repo, 'FAILED', "No such repo #{owner}/#{repo}")
            ght.dispose
            next
          end

          debug("Retrieving repo #{owner}/#{repo}")

          retrieval_stages = %w(ensure_commits ensure_forks ensure_pull_requests
            ensure_issues ensure_project_members ensure_watchers ensure_labels)

          retrieval_stages.each do |x|
            run_retrieval_stage(ght, job_id, owner, repo, x)
          end

          # Repository owner bound data retrieval
          run_retrieval_stage(ght, job_id, owner, repo, 'ensure_user_followers', onlyuser = true)

          if user_entry[:type] == 'ORG'
            run_retrieval_stage(ght, job_id, owner, repo, 'ensure_org', onlyuser = true)
          end

          debug "Finish job_id #{job_id} -> #{owner}/#{repo}"
          send_job_status(job_id, owner, repo, 'FINISHED')
          debug "Sent FINISHED message for  #{job_id} -> #{owner}/#{repo}"
          ght.dispose
        end
      rescue Bunny::TCPConnectionFailed => e
        warn "Connection to #{config(:amqp_host)} failed. Retrying in 1 sec"
        sleep(1)
      rescue Bunny::PossibleAuthenticationFailureError => e
        warn "Could not authenticate as #{conn.username}"
        stopped = true
      rescue Bunny::NotFound, Bunny::AccessRefused, Bunny::PreconditionFailed => e
        warn "Channel error: #{e}. Retrying in 1 sec"
        sleep(1)
      rescue Interrupt => _
        unless job_id.nil?
          send_job_status(job_id, owner, repo, 'STOPPED', 'Retrieval stopped on sysadmin request')
        end
        stopped = true
      rescue Exception => e
        send_email('G.Gousios@tudelft.nl',
                   "job_id: #{job_id}, owner: #{owner}, repo: #{repo}\n" +
                       [e.message, e.backtrace.join("\n")].join("\n\n"))
        send_job_status(job_id, owner, repo, 'FAILED', e.message)
        raise e
      end
    end

    amqp_close
  end

  def send_job_status(job_id, owner, repo, status, details = '')
    amqp_exchange.publish("#{job_id} #{owner} #{repo} #{status} @#{details}@",
                          {:timestamp => Time.now.to_i,
                           :persistent => true,
                           :routing_key => RESULT_QUEUE_ROUTEKEY})
  end

  def run_retrieval_stage(ght, job_id, owner, repo, function, only_user = false)
    begin
      send_job_status(job_id, owner, repo, 'WORKING',
                      "Retrieving #{function.split(/_/)[1..-1].join(' ')}")
      if only_user
        ght.send(function, owner)
      else
        ght.send(function, owner, repo, refresh = false)
      end
    rescue Exception
      warn("Error processing #{function} for #{owner}/#{repo}")
      send_job_status(job_id, owner, repo, 'WORKING',
                      "Failed to retrieve #{function.split(/_/)[1..-1].join(' ')}")
    end
  end

end

GHTServiceRetrieveRepos.run(ARGV)
